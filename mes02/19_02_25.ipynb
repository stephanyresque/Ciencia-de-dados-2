{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Regressão em Machine Learning**\n",
    "\n",
    "Regressão é uma das técnicas fundamentais em machine learning usada para prever valores contínuos. O objetivo principal da regressão é modelar a relação entre uma variável dependente (ou alvo) e uma ou mais variáveis independentes (ou preditoras). Em termos simples, a regressão tenta encontrar uma função matemática que descreva como a saída (a variável dependente) muda em resposta às entradas (as variáveis independentes).\n",
    "\n",
    "Vamos ver o Scikit-Learn: https://scikit-learn.org/stable/\n",
    "\n",
    "## Regressão Linear\n",
    "\n",
    "**1. Regressão Linear Simples:**  \n",
    "Este é o modelo mais básico de regressão, onde se estabelece uma relação linear entre uma única variável independente e a variável dependente. A equação é da forma:\n",
    "\n",
    "$$ y = w_0 + w_1x + \\epsilon $$\n",
    "\n",
    "Onde:\n",
    "- $ y $ é a variável dependente (o valor que queremos prever).\n",
    "- $ x $ é a variável independente.\n",
    "- $ w_0 $ é o intercepto (valor de $ y $ quando $ x = 0 $).\n",
    "- $ w_1 $ é o coeficiente de inclinação (mostra como $ y $ muda com $ x $).\n",
    "- $ \\epsilon $ é o termo de erro, que captura a variabilidade não explicada pelo modelo.\n",
    "\n",
    "**2. Regressão Linear Múltipla:**  \n",
    "Este modelo expande a regressão linear simples para incluir múltiplas variáveis independentes. A equação é:\n",
    "\n",
    "$$ y = w_0 + w_1x_1 + w_2x_2 + \\dots + w_nx_n + \\epsilon $$\n",
    "\n",
    "Aqui, o modelo tenta capturar a relação entre várias entradas $ x_1, x_2, \\dots, x_n $ e a saída $ y $. Embora a relação seja linear, as variáveis independentes podem ser transformadas, por exemplo, elevadas a potências, para capturar padrões mais complexos, mantendo-se ainda dentro do escopo da regressão linear.\n",
    "\n",
    "## Outros Modelos de Regressão\n",
    "\n",
    "**1. Regressão Ridge e Lasso:**  \n",
    "Esses são modelos lineares que adicionam um termo de regularização à função de custo, penalizando coeficientes grandes. Além de reduzir o overfitting, a regularização também ajuda a melhorar a generalização do modelo e a lidar com colinearidade entre as variáveis independentes.\n",
    "\n",
    "- **Ridge:** Penaliza o quadrado dos coeficientes ($\\lambda \\sum w_i^2$), o que tende a manter todos os coeficientes pequenos, mas diferentes de zero.\n",
    "- **Lasso:** Penaliza o valor absoluto dos coeficientes ($\\lambda \\sum |w_i|$), o que pode resultar em coeficientes exatamente iguais a zero, efetivamente realizando seleção de variáveis, além de simplificar o modelo.\n",
    "\n",
    "**2. Regressão de Vetores de Suporte (SVR):**  \n",
    "O SVR é uma extensão do algoritmo de Support Vector Machine (SVM) para problemas de regressão. Ele tenta encontrar uma função que tenha pelo menos uma margem de erro máxima em torno do modelo, e ao mesmo tempo seja tão plana quanto possível.\n",
    "\n",
    "**3. Regressão Logística:**  \n",
    "A regressão logística é usada para prever variáveis categóricas, especialmente binárias (0 ou 1). Embora o nome sugira uma relação com a regressão linear, a saída é transformada usando a função logística:\n",
    "\n",
    "$$ p(x) = \\frac{1}{1 + e^{-(w_0 + w_1x)}} $$\n",
    "\n",
    "Onde $ p(x) $ é a probabilidade de um evento ocorrer. A regressão logística, portanto, é uma técnica de classificação que se encaixa no escopo de regressão apenas conceitualmente, pois modela a relação entre as variáveis independentes e a probabilidade de uma classe específica.\n",
    "\n",
    "**4. Regressão de Árvores de Decisão e Random Forest:**  \n",
    "As árvores de decisão para regressão segmentam repetidamente os dados em subconjuntos baseados em variáveis explicativas, criando uma árvore de decisões que tenta prever o valor da variável dependente. O Random Forest é um conjunto de múltiplas árvores de decisão, agregando seus resultados para uma previsão mais robusta.\n",
    "\n",
    "**5. Regressão com Redes Neurais:**  \n",
    "As redes neurais podem ser usadas para regressão ao adaptar sua arquitetura para prever valores contínuos. Elas podem capturar relações muito complexas entre as variáveis de entrada e a saída, mas são mais difíceis de treinar e ajustar.\n",
    "\n",
    "## Diferenciação entre Modelos\n",
    "\n",
    "- **Simples vs. Múltipla:** A regressão simples lida com uma única variável independente, enquanto a múltipla lida com várias.\n",
    "- **Linear vs. Não Linear:** A regressão linear assume uma relação linear entre as variáveis, enquanto modelos não lineares capturam relações mais complexas.\n",
    "- **Regularização (Ridge e Lasso):** Usado para evitar overfitting, melhorar a generalização do modelo e lidar com colinearidade entre variáveis.\n",
    "- **Complexidade:** Modelos como redes neurais e SVR podem capturar padrões mais complexos, mas demandam maior poder computacional e cuidado na implementação.\n",
    "- **Árvores de Decisão vs. Modelos Lineares:** As árvores de decisão são mais interpretáveis, mas podem ser menos precisas em certos contextos, especialmente sem ensemble methods como o Random Forest.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
